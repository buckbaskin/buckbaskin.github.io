<!DOCTYPE html>
<html lang="en">
<head>
          <title>FormaK Under The Hood: Optimization for scikit-learn integration - Building and Breaking</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="/blog/theme/css/si
te.css" />
        <meta name="tag" content="tag data">
        <meta name="twitter:card" content="summary"></meta>
        <meta name="twitter:site" content="@beBaskin"></meta>
        <meta name="twitter:image" content="https://avatars2.githubusercontent.com/u/3441311?s=400&v=4"></meta>
        <link href="https://buckbaskin.com/blog/feed" type="application/rss+xml" rel="alternate" title="Building and Breaking Full RSS Feed" />

    <meta name="twitter:creator" content="@beBaskin"></meta>
    <meta name="twitter:title" content="FormaK Under The Hood: Optimization for scikit-learn integration - Building and Breaking"></meta>
    <meta name="description" content="<p>For the new scikit-learn feature, let's dive into how the model gets fit to data.</p>" />
    <meta name="twitter:description" content="<p>For the new scikit-learn feature, let's dive into how the model gets fit to data.</p>"></meta>

    <meta name="tags" content="FormaK" />
    <meta name="tags" content="Project FormaK" />
    <meta name="tags" content="30 for 30" />
    <meta name="tags" content="Python" />
    <meta name="tags" content="Scikit-Learn" />
    <meta name="tags" content="Scipy" />
    <meta name="tags" content="optimization" />

</head>

<body id="index" class="home">
        <a href="#content" class="skip">Skip to main content</a>
        <header id="banner" class="body" aria-label="Site Title">
                <h1 class="title"><a href="/blog/">Building and Breaking <strong></strong></a></h1>
        </header><!-- /#banner -->
        <div class="main">
        <main id="content" aria-labelledby="main-title">
<div class="body">
  <header>
    <h1 id="main-title" class="entry-title">FormaK Under The Hood: Optimization for scikit-learn integration - <a href="/blog/category/building.html">Building</a></h1>
 
  </header>
  <footer class="post-info">
    <time class="published" datetime="2022-10-08T00:00:00-07:00">
      Sat 08 October 2022
    </time>
    <address class="vcard author">
      By           <a class="url fn" href="/blog/author/buck-baskin.html">Buck Baskin</a>
    </address>
    <div class="tags">
            <a href="/blog/tag/formak.html">FormaK</a>
            <a href="/blog/tag/project-formak.html">Project FormaK</a>
            <a href="/blog/tag/30-for-30.html">30 for 30</a>
            <a href="/blog/tag/python.html">Python</a>
            <a href="/blog/tag/scikit-learn.html">Scikit-Learn</a>
            <a href="/blog/tag/scipy.html">Scipy</a>
            <a href="/blog/tag/optimization.html">optimization</a>
    </div>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p><a href="/blog/formak-under-the-hood-optimization-for-scikit-learn-integration.html" rel="bookmark"
         title="Permalink to FormaK Under The Hood: Optimization for scikit-learn integration">permalink</a></p>
    <p>One of the common interfaces, perhaps the common interface, of scikit-learn is
<code>fit(X, y)</code>, which updates the estimator's internal parameters to fit some data
(potentially based on other hyper-parameters, like say a symbolic model of the
system).</p>
<p>FormaK assesses the model quality and elects model parameters that best fit the
data. In order to do that, the FormaK library implements a Kalman filter
implementation for quantifying and assessing errors in a structured way. This
is similar to some of scikit-learn's functionality
(<a href="https://scikit-learn.org/stable/modules/covariance.html#covariance">Covariance</a>
for example), but adds a stronger model-first capability by integrating a
process model (the symbolic model) and "sensors" for translating that process
state into the format that data enters the system.</p>
<p>Where this doesn't immediately line up is in selecting the parameters for the
Kalman filter. We have a model of how the system moves through the state space,
we have a state and we have data, but how do we get a <code>fit</code>?</p>
<p>Skip to the <a href="#summary">Summary</a> if you just want to see how to get this in FormaK</p>
<h1 id="part-1-what-are-we-fitting">Part 1: What are we fitting?<a class="headerlink" href="#part-1-what-are-we-fitting" title="Permanent link">¶</a></h1>
<p>The Kalman Filter provides an additional benefit that I glossed over earlier:
it tracks the covariance for the state and, via the sensor models, the
covariance quantifies the expected error distribution for each new data point.
The error between the predicted measurement and the reading is called the
innovation and the score for how that matches the distribution is the
<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.mahalanobis.html">Mahalanobis distance</a>.</p>
<p>Normally approach approaches zero; however, for the Kalman filter model we
actually want to approach mean zero and standard deviation of 1 when normalized
by the expected variance.  Zero mean and standard deviation of 1 indicates that
we don't have any biases in the model and our assessment of the noise in the
system matches the noise in the data.</p>
<p>A loss function for the variance that looks something like this would be ideal:</p>
<p><img alt="Curve with minimum at x=1" src="/blog/img/hand-innovation-loss-function.jpg" class="wideimage"/></p>
<p>One possible function: <code>( 1 / x + x ) / 2</code></p>
<p>As the function approaches 0, the 1/x term dominates and as x grows, x
dominates. Together, the functions combine to produce a minima at x=1 (and
equal to y=1 with the /2 term).</p>
<h1 id="part-2-optimization">Part 2: Optimization<a class="headerlink" href="#part-2-optimization" title="Permanent link">¶</a></h1>
<p>We have a metric where we can look at our data and understand if it's a
good fit or not for the model: the Mahalanobis distance. What's next?</p>
<p>FormaK gets a big leap forward by standing on the shoulders of giants: <code>scipy</code>
provides a general algorithm for optimizing once we have a metric, called
<code>minimize</code>. FormaK provides a function to calculate the metric (would you look
at that, we've got this covered with the Mahalanobis distance) and the initial
state from which to start the optimization.</p>
<p>The initial state isn't quite the state of the Kalman Filter (although that can
be a part of it). Instead, to match the optimization problem we're considering
(the mapping from choices of noise parameters to innovation outcomes) FormaK
uses a state made up of the noise parameters for the model.</p>
<h1 id="part-3-results">Part 3: Results<a class="headerlink" href="#part-3-results" title="Permanent link">¶</a></h1>
<p>To test out the optimization at a high level, I've set up a simple test case.
The data is pretty arbitrary and set around a simple model of position,
velocity and acceleration. The 
<a href="https://github.com/buckbaskin/formak/blob/5116eae67644cacce1a26847219cc35682d38da3/featuretests/scikit_learn_integration/simple_regression_test.py#L32-L51">code to run the fit</a> 
looks something like this:</p>
<pre><code>model = python.compile_ekf(
    ui.Model(dt=dt, state=state, control=control, state_model=state_model), **params
)

readings = X = np.array([[10, 0, 0], [10, 0, 1], [9, 1, 2]])

# Fit the model to data
model.fit(readings)

fit_score = model.score(readings)

assert fit_score &lt; unfit_score
</code></pre>
<p>And the 
<a href="https://github.com/buckbaskin/formak/blob/5116eae67644cacce1a26847219cc35682d38da3/py/formak/python.py#L429-L453">optimization code</a>
looks something like this:</p>
<pre><code># Fit the model to data
def fit(self, X, y=None, sample_weight=None):
    dt = 0.1

    x0 = self._flatten_scoring_params(self.params)
    def minimize_this(x):
        holdout_params = dict(self.get_params())

        scoring_params = self._inverse_flatten_scoring_params(x)
        self.set_params(**scoring_params)

        score = self.score(X, y, sample_weight)

        self.set_params(**holdout_params)
        return score

    minimize_this(x0)

    result = minimize(minimize_this, x0)

    if not result.success:
        print("success", result.success, result.message)
        assert result.success

    soln_as_params = self._inverse_flatten_scoring_params(result.x)
    self.set_params(**soln_as_params)

    return self

def score(self, X, y=None, sample_weight=None):
    state = np.zeros((self.state_size, 1))
    covariance = np.eye(self.state_size)

    innovations = []

    for idx in range(X.shape[0]):
        controls_input, the_rest = (
            X[idx, : self.control_size],
            X[idx, self.control_size :],
        )
        state, covariance = self.process_model(
            dt, state, covariance, controls_input
        )

        innovation = []

        for key in sorted(list(self.params["sensor_models"])):
            sensor_size = len(self.params["sensor_models"][key])

            sensor_input, the_rest = (
                the_rest[:sensor_size],
                the_rest[sensor_size:],
            )
            state, covariance = self.sensor_model(
                key, state, covariance, sensor_input
            )

            # Normalized by the uncertainty at the time of the measurement
            innovation.append(
                np.matmul(
                    self.innovations[key],
                    np.linalg.inv(self.sensor_prediction_uncertainty[key]),
                )
            )

        innovations.append(innovation)

    x = np.sum(np.square(innovations))

    # minima at x = 1, innovations match noise model
    return (1.0 / x + x) / 2.0
</code></pre>
<p>This took some tweaking to get right, but the outcome is going from an error
score of 1.29 down to 1.00. It's only a couple of data points, so the numbers
aren't meaningful, but we can see that the minimization is working to decrease
the model error by manipulating the noise parameters.</p>
<h1 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">¶</a></h1>
<p>Under the hood of the <code>fit</code> interface Formak uses an optimization algorithm
working on your behalf to pick model parameters based on your data.</p>
<p>To use this with FormaK, all you have to do is define your model and call fit
on your data.</p>
<pre><code># define physics
physics_model = {
    x: x + dt * v,
    v: v,
}
# load some data
data = ...
# prepare the model
model = python.compile_ekf(
    ui.Model(dt=dt, state=state, control=control, state_model=physics_model), **params
)
physics_model.fit(data)
# profit
</code></pre>
<p>From there, you're off to the races working with an optimal model :)</p>
<p>If you want to try this out, check out the 
<a href="https://github.com/buckbaskin/formak/pull/3">pull request</a> or play with the 
branch
<a href="https://github.com/buckbaskin/formak/tree/sklearn-integration"><code>sklearn-integration</code></a>
When you try it out, if you find any bugs or have questions, please 
<a href="https://github.com/buckbaskin/formak/issues">open an issue</a> on Github</p>
  </div><!-- /.entry-content -->
</div>
        </main><!-- /#content -->
        </div>
        <footer id="contentinfo" class="body">
                <author>
                        If you liked this and want to see more, let me know
                        <a href="https://twitter.com/beBaskin">@beBaskin</a> 
                        on Twitter. Check out the 
                        <a href="/blog/projects.html">projects</a>!
                </author><!-- /#about -->
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>. Hosted on <a href="https://pages.github.com/">Github Pages</a>.
                </address><!-- /#author -->
        </footer><!-- /#contentinfo -->
</body>
</html>