<!DOCTYPE html>
<html lang="en">
<head>
          <title>SIMD and Graphs: Partitioning Graphs into data-dependency levels - Building and Breaking</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="/blog/theme/css/si
te.css" />
        <meta name="tag" content="tag data">
        <meta name="twitter:card" content="summary"></meta>
        <meta name="twitter:site" content="@beBaskin"></meta>
        <meta name="twitter:image" content="https://avatars2.githubusercontent.com/u/3441311?s=400&v=4"></meta>
        <link href="https://buckbaskin.com/blog/feed" type="application/rss+xml" rel="alternate" title="Building and Breaking Full RSS Feed" />

    <meta name="twitter:creator" content="@beBaskin"></meta>
    <meta name="twitter:title" content="SIMD and Graphs: Partitioning Graphs into data-dependency levels - Building and Breaking"></meta>
    <meta name="description" content="<p>This post is a new episode in a miniseries focused on SIMD instructions. This second post focuses on fusing common single operations across multiple data</p>" />
    <meta name="twitter:description" content="<p>This post is a new episode in a miniseries focused on SIMD instructions. This second post focuses on fusing common single operations across multiple data</p>"></meta>

    <meta name="tags" content="Miniseries" />
    <meta name="tags" content="FormaK" />
    <meta name="tags" content="Graphs" />
    <meta name="tags" content="SIMD" />

</head>

<body id="index" class="home">
        <a href="#content" class="skip">Skip to main content</a>
        <header id="banner" class="body" aria-label="Site Title">
                <h1 class="title"><a href="/blog/">Building and Breaking <strong></strong></a></h1>
        </header><!-- /#banner -->
        <div class="main">
        <main id="content" aria-labelledby="main-title">
<div class="body">
  <header>
    <h1 id="main-title" class="entry-title">SIMD and Graphs: Partitioning Graphs into data-dependency levels - <a href="/blog/category/building.html">Building</a></h1>
 
  </header>
  <footer class="post-info">
    <time class="published" datetime="2022-11-26T00:00:00-08:00">
      Sat 26 November 2022
    </time>
    <address class="vcard author">
      By           <a class="url fn" href="/blog/author/buck-baskin.html">Buck Baskin</a>
    </address>
    <div class="tags">
            <a href="/blog/tag/miniseries.html">Miniseries</a>
            <a href="/blog/tag/formak.html">FormaK</a>
            <a href="/blog/tag/graphs.html">Graphs</a>
            <a href="/blog/tag/simd.html">SIMD</a>
    </div>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p><a href="/blog/simd-and-graphs-partitioning-graphs-into-data-dependency-levels.html" rel="bookmark"
         title="Permalink to SIMD and Graphs: Partitioning Graphs into data-dependency levels">permalink</a></p>
    <p>This post is a new episode in a miniseries focused on SIMD
instructions. This post focuses on fusing common single operations
across multiple data. If you haven't read the first post, I recommend reading
the <a href="/blog/simd-and-graphs-graph-matching.html">first post</a> on graph matching
first.
1. <a href="/blog/simd-and-graphs-graph-matching.html">Parse the sympy graph into a subset of pattern matches with partial orderings of patterns that contain (depend upon) other patterns</a>
2. Perform common subexpression elimination to deduplicate computations
3. Run the Coffman-Graham algorithm to get a bounded nearly optimal allocation of the matches (This post)
4. Edit the SIMD compute node in place of matching patterns</p>
<p>SIMD (Single Instruction Multiple Data) looks to speed up performing the same
calculation across multiple sets of data. Now that we have operations that
match the SIMD operation, how do we know which nodes in the graph we can
combine? We need to respect data dependencies to make sure that we don't try
to do two operations that depend on each other or perform a computation before
its inputs are ready.</p>
<p>Skip to <a href="#a-solution">a solution</a></p>
<h1 id="missteps">Missteps<a class="headerlink" href="#missteps" title="Permanent link">¶</a></h1>
<p>A brief note on the missteps: These are avenues that I didn't explore or bugs
that I ran across. While not immediately helpful, they may form a bridge to
future ideas in the series.</p>
<h2 id="a-bug-when-it-comes-to-matching">A bug when it comes to matching<a class="headerlink" href="#a-bug-when-it-comes-to-matching" title="Permanent link">¶</a></h2>
<p>If the matching provided by the end user is too strict, it can result in an
empty set of "ordered nodes". From there, there is no ordering between the
following nodes added to the list. The symptom of this is to add nodes to levels
in the wrong order and miss dependencies. The easiest place to check for this is
at the end of the setup by asserting that there are ordered nodes before trying
to add in nodes with dependencies. This was tricky to find because it originally
showed up in a way that made it look like the dependency checking was not
working.</p>
<h2 id="graph-uniqueness">Graph uniqueness<a class="headerlink" href="#graph-uniqueness" title="Permanent link">¶</a></h2>
<p>The algorithm currently doesn't interface well with common subexpression
elimination. This would lead to nodes being referred to through multiple paths
in the graph and cause the node identification via path to break down.</p>
<h2 id="crossover-between-simd-operations">Crossover between SIMD operations<a class="headerlink" href="#crossover-between-simd-operations" title="Permanent link">¶</a></h2>
<p>This algorithm focuses on introducing operations for a single type of SIMD
operation. Further design will be needed for choosing between multiple
operations. For example, some SIMD operations perform an add and multiply and
different SIMD operations operate at different precisions.</p>
<h1 id="a-solution">A Solution<a class="headerlink" href="#a-solution" title="Permanent link">¶</a></h1>
<p><a href="https://github.com/buckbaskin/formak/pull/6/files">Github PR</a></p>
<p>The algorithm of choice for this kind of bundling is the
<a href="https://mathweb.ucsd.edu/~ronspubs/72_04_two_processors.pdf">Coffman-Graham</a>
algorithm. It's original intent is to schedule minimal-length schedules across
multiple processors for a known finite number of processors; however, we can
bend it slightly to adapt it to SIMD algorithms where we have multiple processor
lanes as long as the data is independent. Even better, the algorithm is
demonstrated to be optimal.</p>
<h2 id="the-algorithm">The Algorithm<a class="headerlink" href="#the-algorithm" title="Permanent link">¶</a></h2>
<p>The Coffman-Graham algorithm breaks down into two phases:
1. Topological Sort
2. Leveling</p>
<h3 id="topological-sort">Topological Sort<a class="headerlink" href="#topological-sort" title="Permanent link">¶</a></h3>
<p>In the first phase, nodes in the compute graph are ordered based on their dependencies
(topological sort) with a special lexicographical ordering: Take nodes that had
their dependencies recently added to the sorted ordering before nodes with less
recent dependencies. Intuitively, this has the effect of performing a
depth-first ordering of the data dependencies to order longer chains earlier and
bundle together chains of dependencies.</p>
<pre><code>ordered_nodes, unordered_nodes = setup_coffman_graham(graph, matcher)
assert len(ordered_nodes) &gt; 0

def coffman_graham_filter_criteria(node):
    path_to_expr, expr = node

    for idx in range(len(expr.args)):
        if tuple(path_to_expr + (idx,)) in unordered_nodes:
            # Don't try to insert nodes that depend on unordered nodes
            return False

    # Node only depends on ordered nodes
    return True

def coffman_graham_sort_criteria(node):
    path_to_expr, expr = node
    args_depth_from_end = []

    for arg_idx, arg in enumerate(expr.args):
        arg_path = path_to_expr + (arg_idx,)
        for ordered_idx, (ordered_path, ordered_expr) in enumerate(
            reversed(ordered_nodes)
        ):
            if arg_path == ordered_path:
                args_depth_from_end.append(ordered_idx)
                break

    return sorted(args_depth_from_end)

while len(unordered_nodes) &gt; 0:
    next_in_order = min(
        filter(coffman_graham_filter_criteria, unordered_nodes.items()),
        key=coffman_graham_sort_criteria,
    )
    path, _expr = next_in_order

    ordered_nodes.append(next_in_order)
    del unordered_nodes[tuple(path)]
</code></pre>
<h3 id="leveling">Leveling<a class="headerlink" href="#leveling" title="Permanent link">¶</a></h3>
<p>In the second phase, nodes are processed in the reversed order from the first
phase. Nodes are assigned to the lowest possible level that is at least one
level above their downstream dependencies. The ordering of the first phase leads
us to the smallest possible level stack (the minimal-length schedule). This is
modified slightly to bump dependencies to the next level if the level is full.</p>
<pre><code>levels = []

for idx, node in enumerate(reversed(ordered_nodes)):
    min_level = -1
    for inv_level_idx, level in enumerate(reversed(levels)):
        for maybe_dependency in level:
            if is_dependency_of(node, maybe_dependency):
                min_level = len(levels) - inv_level_idx - 1
                # need to go to a greater level
                break
        if min_level &gt; -1:
            break

    for level_idx in range(min_level + 1, len(levels)):
        if len(levels[level_idx]) &lt; width:
            levels[level_idx].append(node)
            break
    else:
        # We didn't find an acceptable level, so put it at a new higher level
        levels.append([node])

return levels
</code></pre>
<h2 id="filtervisitor-pattern">FilterVisitor Pattern<a class="headerlink" href="#filtervisitor-pattern" title="Permanent link">¶</a></h2>
<p>This solution leans on the visitor pattern and matching structure from the
previous post to set up the problem, which I'll refer to as the FilterVisitor.</p>
<p>To start the topological sort, we want to create an
ordered list of nodes with no dependencies (leaves, usually symbols and
constants) and an unordered map. By visiting the tree and matching our target
operations, we can push them into the set of unordered operations and push the
leaves into the ordered list.</p>
<pre><code>def visit_sympy_expr(expr, matcher, base=None):
    if base is None:
        base = tuple()

    if matcher(expr):
        yield base, expr

    for idx, arg in enumerate(expr.args):
        for result in visit_sympy_expr(arg, matcher, base + (idx,)):
            yield result
</code></pre>
<p>The matcher used for this example is:</p>
<pre><code>def match_Add(expr):
    return expr.func == sympy.core.add.Add or len(expr.args) == 0
</code></pre>
<h2 id="related-work">Related Work<a class="headerlink" href="#related-work" title="Permanent link">¶</a></h2>
<h3 id="llvm">LLVM<a class="headerlink" href="#llvm" title="Permanent link">¶</a></h3>
<p>LLVM's <a href="https://www.llvm.org/docs/Vectorizers.html">auto-vectorization</a>
focuses on two use cases:
1. Loops
2. superword-level parallelism aka "SLP"</p>
<p>The loop vectorizer case is straightforward: process multiple iterations of a loop
in parallel. The use case I'm covering is closer to the SLP case:</p>
<blockquote>
<p>combine similar independent instructions into vector instructions</p>
</blockquote>
<p>and</p>
<blockquote>
<p>The SLP-vectorizer processes the code bottom-up, across basic blocks, in
search of scalars to combine.</p>
</blockquote>
<p>According to benchmarks by 
<a href="https://www.phoronix.com/news/MTQyMzQ">Michael Larabel</a> from an old version of
LLVM (circa 2013), the SLP vectorization isn't as impactful as the loop
vectorizer.</p>
<h3 id="research-into-superword-level-parallelism">Research into Superword Level Parallelism<a class="headerlink" href="#research-into-superword-level-parallelism" title="Permanent link">¶</a></h3>
<p><a href="https://groups.csail.mit.edu/cag/slp/">This page</a> references three papers for
integrating superword-level parallelism into compilers (circa 2000). For
example, <a href="https://groups.csail.mit.edu/cag/slp/SLP-PLDI-2000.pdf">this paper</a>
and a follow up 
<a href="https://15745-slp-project.github.io/Final.pdf">project to implement it in LLVM</a>
suggest that performance improvements can be gained by being smart about
additional optimization combinations applying SLP that goes beyond what the LLVM
compiler achieves today.</p>
  </div><!-- /.entry-content -->
</div>
        </main><!-- /#content -->
        </div>
        <footer id="contentinfo" class="body">
                <author>
                        If you liked this and want to see more, let me know
                        <a href="https://twitter.com/beBaskin">@beBaskin</a> 
                        on Twitter. Check out the 
                        <a href="/blog/projects.html">projects</a>!
                </author><!-- /#about -->
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>. Hosted on <a href="https://pages.github.com/">Github Pages</a>.
                </address><!-- /#author -->
        </footer><!-- /#contentinfo -->
</body>
</html>